
# 24.7. Caching Response Content

[toc]

## intro

To avoid re-requesting the same data, use a programming pattern known as `caching`.

It works like this:
1. Before doing some expensive operation (like calling requests.get to get data from a REST API), check whether you have already saved (“cached”) the results that would be generated by making that request.
2. If so, return that same data.
3. If not, perform the expensive operation and save (“cache”) the results (e.g. the complicated data) in your cache so you won’t have to perform it again the next time.


reasons why caching is a good idea during your software development using REST APIs:
- `reduces load on the website` that is providing you data. some websites impose rate limits: for example, after 15 requests in a 15 minute period, the site may start sending error responses..
- `make program run faster`. Connections over the Internet can take a few seconds, or even tens of seconds, if you are requesting a lot of data. It might not seem like much, but debugging is a lot easier when you can make a change in your program, run it, and get an almost instant response.
- harder to debug the code that processes complicated data if the content that is coming back can change on each run of your code. It’s amazing to be able to write programs that fetch real-time data like the available iTunes podcasts or the latest tweets from Twitter. But it can be hard to debug that code if you are having problems that only occur on certain Tweets (e.g. those in foreign languages). When you encounter problematic data, it’s helpful if you save a copy and can debug your program working on that saved, static copy of the data.
- easier to run automated tests on code that retrieves data if the data can never change, for the same reasons it is helpful for debugging. In fact, we rely on use of cached data in the automated tests that check your code in exercises.

## 24.7.1. `requests_with_caching` module

statement **to import the module**: `import requests_with_caching`.
- not `requests.get()`, use `requests_with_caching.get()`.
- exactly the same Response object back as `requests.get()`.

But also get a printout in the output window with one of the following three diagnostic messages:
- found in permanent cache
- found in page-specific cache
- new; adding to cache


The `permanent cache` is contained in a file that is built into the textbook. program can use its contents but can’t add to it.


The `page-specific cache` is a new file that is created the first time you make a request for a url that wasn’t in the `permanent cache`.
- Each subsequent request for a new url results in more data being written to the `page-specific cache`.
- After you run an activecode that adds something to the page-specific cache, you’ll see a little window below it where you can inspect the contents of the page-specific cache. When you reload the webpage, that page-specific cache will be gone; hence the name.


optional parameters for function `requests_with_caching.get()`
- `cache_file` – it’s value should be a string specifying the name of the file containing the permanent cache. If you don’t specify anything, the default value is “permanent_cache.txt”. For the datamuse API, we’ve provide a cache in a file called datamuse_cache.txt. It just contains the saved response to the query for “https://api.datamuse.com/words?rel_rhy=funny”.
- `private_keys_to_ignore` – its value should be a list of strings. These are keys from the parameters dictionary that should be ignored when deciding whether the current request matches a previous request. The main purpose of this is that it allows us to return a result from the cache for some REST APIs that would otherwise require you to provide an API key in order to make a request. By default, it is set to [“api_key”], which is a query parameter used with the flickr API. You should not need to set this optional parameter.


```py
import requests_with_caching
# like requests.fet()
# but it check cache first.
# if no chech, it calls requests.fet()

# it's not found in the permanent cache
res = requests_with_caching.get("https://api.datamuse.com/words?rel_rhy=happy", permanent_cache_file="datamuse_cache.txt")
#print(res.text[:100])

# this time it will be found in the temporary cache
res = requests_with_caching.get("https://api.datamuse.com/words?rel_rhy=happy", permanent_cache_file="datamuse_cache.txt")

# This one is in the permanent cache.
res = requests_with_caching.get("https://api.datamuse.com/words?rel_rhy=funny", permanent_cache_file="datamuse_cache.txt")
# result:
found in page-specific cache
#[{"word":"nappy","score":703,"numSyllables":2},{"word":"scrappy","score":700,"numSyllables":2},{"wor
found in page-specific cache
found in permanent_cache

```

---

### 24.7.2. Implementation

to maintain the cache as a dictionary with keys representing API requests that have been made, and values representing the text that was retrieved.

In order to make cache live beyond one program execution, store it in a file. Hence, there are helper functions `_write_to_file` and `read_to_file` that write a cache dictionary to and read it from a file.

In order for the textbook to provide a cache file that can’t be overwritten, distinguish between the `permanent file`, which is provided as part of the online textbook, and a `temporary cache file` that will live only until the page is reloaded.

```py

import json

PERMANENT_CACHE_FNAME = "permanent_cache.txt"
TEMP_CACHE_FNAME = "this_page_cache.txt"

# write cache in fname
def _write_to_file(cache, fname):
    with open(fname, 'w') as outfile:
        outfile.write(json.dumps(cache, indent=2))

# read cache in fname
def _read_from_file(fname):
    try:
        with open(fname, 'r') as infile:
            res = infile.read()
            return json.loads(res)
    except:
        return {}

# add cache_key, cache_value to cache_file, rewrite it
def add_to_cache(cache_file, cache_key, cache_value):
    temp_cache = _read_from_file(cache_file)
    temp_cache[cache_key] = cache_value
    _write_to_file(temp_cache, cache_file)


def clear_cache(cache_file=TEMP_CACHE_FNAME):
    _write_to_file({}, cache_file)


def make_cache_key(baseurl, params_d, private_keys=["api_key"]):
    """Makes a long string representing the query.
    Alphabetize the keys from the params dictionary so we get the same order each time.
    Omit keys with private info."""
    alphabetized_keys = sorted(params_d.keys())
    res = []
    for k in alphabetized_keys:
        if k not in private_keys:
            res.append("{}-{}".format(k, params_d[k]))
    return baseurl + "_".join(res)
# Because when requests.get encodes URL parameters, the keys in the params dictionary might be in any order, which would make it hard to compare one URL to another later on, and you could cache the same request multiple times.
# Comparing the strings "rowling&harry+potter" and "harry+potter&rowling", different for Python but same for REST API
# need to manipulate these strings carefully to always get the same, canonical key for the cache dictionary.


def get(baseurl, params={}, private_keys_to_ignore=["api_key"], permanent_cache_file=PERMANENT_CACHE_FNAME, temp_cache_file=TEMP_CACHE_FNAME):
    full_url = requests.requestURL(baseurl, params)
    cache_key = make_cache_key(baseurl, params, private_keys_to_ignore)
    # Load the permanent and page-specific caches from files
    permanent_cache = _read_from_file(permanent_cache_file)
    temp_cache = _read_from_file(temp_cache_file)
    if cache_key in temp_cache:
        print("found in temp_cache")
        # make a Response object containing text from the change, and the full_url that would have been fetched
        return requests.Response(temp_cache[cache_key], full_url)
    elif cache_key in permanent_cache:
        print("found in permanent_cache")
        # make a Response object containing text from the change, and the full_url that would have been fetched
        return requests.Response(permanent_cache[cache_key], full_url)
    else:
        print("new; adding to cache")
        # actually request it
        resp = requests.get(baseurl, params)
        # save it
        add_to_cache(temp_cache_file, cache_key, resp.text)
        return resp
```
















.
